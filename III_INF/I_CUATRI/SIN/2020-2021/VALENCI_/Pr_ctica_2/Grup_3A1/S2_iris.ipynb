{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl4q0Ev7pTAK"
   },
   "source": [
    "# Perceptró aplicat a iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTW8YdnCpTAO"
   },
   "source": [
    "**Lectura del corpus:** $\\;$ comprovem també que les matrius de dades i etiquetes tenes les files i columnes que toca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZs94_F7pTAO"
   },
   "outputs": [],
   "source": [
    "# Importar la biblioteca numpy i assignar-li l'àlies 'np' per facilitar el seu ús posterior.\n",
    "import numpy as np\n",
    "\n",
    "# Importar la funció 'load_iris' del mòdul 'datasets' de la biblioteca 'sklearn'.\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Carregar el conjunt de dades Iris i emmagatzemar-lo en la variable 'iris'.\n",
    "iris = load_iris()\n",
    "\n",
    "# Accedir a les dades de característiques (features) del conjunt de dades Iris, i convertir-les a 'float16'\n",
    "X = iris.data.astype(np.float16)\n",
    "\n",
    "# Accedir a les etiquetes (objectius), convertir-les al tipus de dada 'uint' i remodelar-les perquè siguen una matriu d'una columna\n",
    "y = iris.target.astype(np.uint).reshape(-1, 1)\n",
    "\n",
    "# Imprimir la forma (dimensions) de les matrius 'X' i 'y', seguit de les primeres 5 files\n",
    "print(X.shape, y.shape, \"\\n\", np.hstack([X, y])[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flPuzHjjpTAP"
   },
   "source": [
    "**Partició del corpus:** $\\;$ Creem un split d'iris amb un $20\\%$ de dades per a test i la resta per a entrenament (training), barallant prèviament les dades d'acord amb una llavor donada per a la generació de nombres aleatoris. Ací, com en tot codi que incloga aleatorietat (que requerisca generar nombres aleatoris), convé fixar la dita llavor per a poder reproduir experiments amb exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyKh9w2SpTAQ"
   },
   "outputs": [],
   "source": [
    "# Importar la funció 'train_test_split' del mòdul 'model_selection' de la biblioteca 'sklearn'.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir els conjunts de dades de característiques (X) i etiquetes (y) en subconjunts d'entrenament i prova.\n",
    "# El paràmetre 'test_size=0.2' indica que el 20% de les dades s'utilitzarà com a conjunt de prova, el 80% restant serà el conjunt d'entrenament.\n",
    "# El paràmetre 'shuffle=True' assegura que les dades es barregen abans de dividir-les, la qual cosa és important per evitar sesgos.\n",
    "# El paràmetre 'random_state=23' s'utilitza per garantir la reproductibilitat del procés de divisió.\n",
    "# Els conjunts d'entrenament i prova resultants s'emmagatzemen en 'X_train', 'X_test', 'y_train' i 'y_test', respectivament.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n",
    "\n",
    "# Imprimir les dimensions dels conjunts d'entrenament i prova de les característiques (X), mostrant informació sobre quantes mostres hi ha en cada conjunt.\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSJj_93tpTAQ"
   },
   "source": [
    "**Implementació de Perceptró:** $\\;$ torna pesos en notació homogènia, $\\mathbf{W}\\in\\mathbb{R}^{(1+D)\\times C};\\;$ també el nombre d'errors i iteracions executades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRMmtKHCpTAR"
   },
   "outputs": [],
   "source": [
    "def perceptron(X, y, b=0.1, a=1.0, K=200):\n",
    "    # X: Matriu de característiques d'entrada.\n",
    "    # y: Vector d'etiquetes.\n",
    "    # b: Marge de classificació.\n",
    "    # a: Taxa d'aprenentatge.\n",
    "    # K: Número màxim d'iteracions.\n",
    "\n",
    "    N, D = X.shape  # N: Nombre de mostres, D: Nombre de característiques.\n",
    "    Y = np.unique(y)  # Y: Etiquetes úniques en el conjunt de dades.\n",
    "    C = Y.size  # C: Nombre de classes úniques.\n",
    "    W = np.zeros((1+D, C))  # W: Matriu de pesos inicialitzada a zeros.\n",
    "\n",
    "    for k in range(1, K+1):  # Bucle sobre les iteracions.\n",
    "        E = 0  # E: Comptador d'errors en la classificació.\n",
    "\n",
    "        for n in range(N):  # Bucle sobre totes les mostres.\n",
    "            xn = np.array([1, *X[n, :]])  # xn: Vector de característiques amb un terme independent afegit.\n",
    "            cn = np.squeeze(np.where(Y==y[n]))  # cn: Índex de la classe actual de la mostra.\n",
    "            gn = W[:,cn].T @ xn  # gn: Producte punt de la mostra amb els pesos de la seua classe.\n",
    "            err = False  # err: Indicador d'error en la classificació.\n",
    "\n",
    "            # Bucle per actualitzar els pesos si es troba un error.\n",
    "            for c in np.arange(C):\n",
    "                if c != cn and W[:,c].T @ xn + b >= gn:\n",
    "                    W[:, c] = W[:, c] - a*xn  # Actualitzar pesos per classes incorrectes.\n",
    "                    err = True\n",
    "\n",
    "            # Actualitzar pesos per la classe correcta si es va trobar un error.\n",
    "            if err:\n",
    "                W[:, cn] = W[:, cn] + a*xn\n",
    "                E = E + 1  # Incrementar el comptador d'errors.\n",
    "\n",
    "        # Si no hi ha errors, aturar l'entrenament.\n",
    "        if E == 0:\n",
    "            break;\n",
    "\n",
    "    return W, E, k  # Tornar la matriu de pesos, el nombre d'errors i el nombre d'iteracions realitzades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSej9LcupTAR"
   },
   "source": [
    "**Aprenentatge d'un classificador (lineal) amb Perceptró:** $\\;$ Perceptró minimitza el nombre d'errors d'entrenament (amb marge)\n",
    "$$\\mathbf{W}^*=\\operatorname*{argmin}_{\\mathbf{W}=(\\boldsymbol{w}_1,\\dotsc,\\boldsymbol{w}_C)}\\sum_n\\;\\mathbb{I}\\biggl(\\max_{c\\neq y_n}\\;\\boldsymbol{w}_c^t\\boldsymbol{x}_n+b \\;>\\; \\boldsymbol{w}_{y_n}^t\\boldsymbol{x}_n\\biggr)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUzbukQ7pTAR"
   },
   "outputs": [],
   "source": [
    "W, E, k = perceptron(X_train, y_train)\n",
    "print(\"Nombre d'iteracions executades: \", k)\n",
    "print(\"Nombre d'errors d'entrenament: \", E)\n",
    "print(\"Vectors de pesos de les classes (en columnes i amb notació homogènia):\\n\", W);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLmjWQjFpTAS"
   },
   "source": [
    "**Càlcul de la taxa d'error en test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKaHSnXFpTAS"
   },
   "outputs": [],
   "source": [
    "# Preparar el conjunt de dades de prova (X_test) per a la classificació.\n",
    "# Això es fa afegint una columna d'uns a l'inici de X_test.\n",
    "# La columna d'uns actua com el terme independent en la normalització per al model de perceptró.\n",
    "X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
    "\n",
    "# Realitzar la predicció en el conjunt de prova.\n",
    "# Això es fa calculant el producte (usant l'operador '@') entre X_testh i la matriu de pesos W.\n",
    "# La funció 'np.argmax' s'utilitza per seleccionar l'índex de la classe amb el valor més alt en cada fila, el que correspon a la classe predita pel model.\n",
    "# Els resultats es reformen en una matriu d'una columna.\n",
    "y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
    "\n",
    "# Calcular la taxa d'error de les prediccions.\n",
    "# Això es fa comptant el nombre de vegades que les prediccions (y_test_pred) difereixen de les etiquetes veritables (y_test),\n",
    "# i dividint aquest nombre per la longitud del conjunt de prova (X_test).\n",
    "# El resultat és la proporció de prediccions incorrectes.\n",
    "err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
    "\n",
    "# Imprimir la taxa d'error en el conjunt de prova.\n",
    "# El resultat es mostra com un percentatge amb un decimal.\n",
    "print(f\"Taxa d'error en test: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKL6wxdtpTAS"
   },
   "source": [
    "**Ajust del marge:** $\\;$ experiment per a aprendre un valor de $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH97MY7fpTAS"
   },
   "outputs": [],
   "source": [
    "# Bucle sobre diferents valors del paràmetre de marge 'b'.\n",
    "for b in (.0, .01, .1, 10, 100):\n",
    "    # Entrenar el perceptró amb el conjunt d'entrenament (X_train, y_train), utilitzant el valor actual de 'b' i un límit màxim de 1000 iteracions.\n",
    "    # La funció 'perceptron' retorna la matriu de pesos 'W', el nombre d'errors 'E' i el nombre d'iteracions 'k'.\n",
    "    W, E, k = perceptron(X_train, y_train, b=b, K=1000)\n",
    "\n",
    "    # Imprimir el valor actual de 'b', el nombre d'errors 'E', i el nombre d'iteracions 'k' per a cada entrenament.\n",
    "    print(b, E, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNkDPvAUpTAT"
   },
   "source": [
    "**Interpretació de resultats:** $\\;$ les dades d'entrenament no semblen linealment separables; no està clar que un marge major que zero puga millorar resultats, sobretot perquè sols tenim $30$ mostres de test; amb marge nul ja hem vist que s'obté un error (en test) del $16.7\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOr_SjR7sbYy"
   },
   "outputs": [],
   "source": [
    "for b in (.0, .01, .1, 10, 100):\n",
    "\n",
    "    W, E, k = perceptron(X_train, y_train, b=b, K=200)\n",
    "\n",
    "    X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
    "\n",
    "    y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
    "\n",
    "    err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
    "\n",
    "    print(f\"Iteració amb b: {b} Taxa d'error en test: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NG8siEEvtPur"
   },
   "outputs": [],
   "source": [
    "for a in ( .01, .1, 10, 100):\n",
    "\n",
    "    W, E, k = perceptron(X_train, y_train, a=a, K=1000)\n",
    "\n",
    "    X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
    "\n",
    "    y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
    "\n",
    "    err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
    "\n",
    "    print(f\"Iteració amb a: {a} Taxa d'error en test: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxn7p38IthSS"
   },
   "outputs": [],
   "source": [
    "for k in ( 200, 500, 1000, 10000):\n",
    "\n",
    "    W, E, k = perceptron(X_train, y_train, a=0.1, b=10, K=k)\n",
    "\n",
    "    X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
    "\n",
    "    y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
    "\n",
    "    err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
    "\n",
    "    print(f\"Iteració amb k: {k} Taxa d'error en test: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSR9VQ-ot4wH"
   },
   "source": [
    "Quina combinació de valors de a, b i k seleccionaries? Justifica la resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
