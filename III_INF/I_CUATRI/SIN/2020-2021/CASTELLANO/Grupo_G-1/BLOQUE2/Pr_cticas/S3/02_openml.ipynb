{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stw5bLpLL6k0"
      },
      "source": [
        "<p style=\"page-break-after:always;\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdQY9X98L6k2"
      },
      "source": [
        "# Regresión logística aplicada a openml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDcUvwuCL6k2"
      },
      "outputs": [],
      "source": [
        "import warnings; warnings.filterwarnings(\"ignore\"); import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alsdzgOcL6k2"
      },
      "outputs": [],
      "source": [
        "def err_eval(data_id):\n",
        "    X, y = fetch_openml(data_id=data_id, return_X_y=True, as_frame=False, parser=\"liac-arff\")\n",
        "    mask = ~np.isnan(X).any(axis=1); X = X[mask, :]; y = y[mask]\n",
        "    if X.shape[0] < 10: return(1.0)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n",
        "    clf = LogisticRegression(random_state=23).fit(X_train, y_train)\n",
        "    return(1 - accuracy_score(y_test, clf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiwgsz2gL6k3"
      },
      "outputs": [],
      "source": [
        "import openml\n",
        "for sid in (99, 334):\n",
        "    benchmark_suite = openml.study.get_suite(suite_id=sid)\n",
        "    df = openml.datasets.list_datasets(data_id=benchmark_suite.data, output_format='dataframe')\n",
        "    for did, name, C in zip(df['did'], df['name'], df['NumberOfClasses']):\n",
        "        err = err_eval(did)\n",
        "        print(f\"sid: {sid:5d}  did: {did:5d}  C: {C:5.0f}  err: {err:7.1%}  name: {name:s}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYKEKTP-L6k3"
      },
      "source": [
        "<p style=\"page-break-after:always;\"></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAagN6GfL6k4"
      },
      "outputs": [],
      "source": [
        "import openml\n",
        "for sid in (271, ):\n",
        "    benchmark_suite = openml.study.get_suite(suite_id=sid)\n",
        "    df = openml.datasets.list_datasets(data_id=benchmark_suite.data, output_format='dataframe')\n",
        "    for did, name, C in zip(df['did'], df['name'], df['NumberOfClasses']):\n",
        "        if did == 41147: continue;\n",
        "        err = err_eval(did)\n",
        "        print(f\"sid: {sid:5d}  did: {did:5d}  C: {C:5.0f}  err: {err:7.1%}  name: {name:s}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}