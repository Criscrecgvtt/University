{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GtbSt4JhWAZ"
      },
      "source": [
        "# Regresión logística aplicada a iris"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a2uc5NAhWAa"
      },
      "source": [
        "**Lectura del corpus y partición:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o-TwPtAhWAb"
      },
      "outputs": [],
      "source": [
        "# Importar la biblioteca NumPy para cálculos numéricos\n",
        "import numpy as np\n",
        "\n",
        "# Importar la función para cargar el conjunto de datos Iris desde scikit-learn\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Importar la función para dividir datos en conjuntos de entrenamiento y prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "\n",
        "# Extraer las características y convertirlas al tipo de dato float16 para optimizar el uso de memoria\n",
        "X = iris.data.astype(np.float16)\n",
        "\n",
        "# Extraer las etiquetas y convertirlas al tipo de dato entero sin signo (uint)\n",
        "y = iris.target.astype(np.uint)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba, con un 20% de los datos como prueba\n",
        "# 'shuffle=True' asegura que los datos se barajen antes de dividirse\n",
        "# 'random_state=23' asegura que la división sea reproducible al usar una semilla específica\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m77jHlXbhWAb"
      },
      "source": [
        "**LogisticRegression:** $\\;$ implementación de regresión logística en sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTb6ZLfwhWAc"
      },
      "outputs": [],
      "source": [
        "# Importar la clase LogisticRegression de scikit-learn para realizar regresión logística\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Importar la función accuracy_score para calcular la precisión de las predicciones\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Crear una instancia del clasificador de regresión logística con una semilla aleatoria para reproducibilidad\n",
        "clf = LogisticRegression(random_state=23).fit(X_train, y_train)\n",
        "\n",
        "# Predecir las etiquetas para el conjunto de datos de prueba\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "# Calcular el error en el conjunto de prueba como 1 menos la precisión\n",
        "err_test = 1 - accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "# Imprimir el error de prueba formateado como un porcentaje con un decimal\n",
        "print(f\"Error de test: {err_test:.1%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0BnYHH4hWAc"
      },
      "source": [
        "**Warnings:** $\\;$ sklearn es un poco \"insistente\" con los warnings; ignoraremos los avisos sobre convergencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfnnL-uvhWAc"
      },
      "outputs": [],
      "source": [
        "# Importar el módulo warnings para controlar las advertencias\n",
        "import warnings\n",
        "\n",
        "# Importar ConvergenceWarning de sklearn.exceptions para capturar advertencias específicas de convergencia\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "# Configurar el módulo warnings para ignorar todas las advertencias de la categoría ConvergenceWarning que provienen de la biblioteca sklearn\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RUiDOZbhWAd"
      },
      "source": [
        "**Solvers:** $\\;$ el parámetro `solver` de LogisticRegression permite elegir entre diferentes solvers (algoritmos de optimitzación)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0ylZ0wOhWAd"
      },
      "outputs": [],
      "source": [
        "# Definir una lista de solvers a probar con el modelo de regresión logística\n",
        "for solver in ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']:\n",
        "    # Crear y entrenar el modelo de regresión logística con cada solver\n",
        "    # 'max_iter=10000' establece un número alto de iteraciones para permitir la convergencia\n",
        "    clf = LogisticRegression(random_state=23, solver=solver, max_iter=10000).fit(X_train, y_train)\n",
        "\n",
        "    # Predecir las etiquetas para el conjunto de prueba y calcular el error\n",
        "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
        "\n",
        "    # Imprimir el error de prueba para cada solver\n",
        "    print(f\"Error de test después de entrenar con el solver {solver!s}: {err_test:.1%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGDde8vAhWAe"
      },
      "source": [
        "**Tolerancia:** $\\;$ el parámetro `tol` establece un umbral de tolerancia para acabar el entrenamiento (1e4 por defecto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GEqjTJkhWAf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Iterar sobre una lista de diferentes valores de tolerancia para el criterio de parada\n",
        "for tol in (1e-4, 1e-2, 1, 1e2, 1e4):\n",
        "    # Crear y entrenar el modelo de regresión logística con cada valor de tolerancia\n",
        "    # 'tol' define el criterio de parada para la optimización: el proceso se detiene cuando el error es menor que 'tol'\n",
        "    clf = LogisticRegression(tol=tol, random_state=23, max_iter=10000).fit(X_train, y_train)\n",
        "\n",
        "    # Predecir las etiquetas para el conjunto de prueba y calcular el error\n",
        "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
        "\n",
        "    # Imprimir el error de prueba para cada valor de tolerancia\n",
        "    print(f\"Error de test con tolerancia {tol}: {err_test:.1%}\")\n",
        "\n",
        "# Los valores de 'tol' van desde muy pequeños (1e-4) hasta muy grandes (1e4), lo que permite evaluar cómo la precisión del modelo varía con diferentes criterios de parada en la optimización.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGuDtw3DhWAf"
      },
      "source": [
        "**Regularización:** $\\;$ el parámetro `C` (positivo, $1.0$ por defecto) des-regulariza el criterio de entrenamiento\n",
        "* **Posibilidad de subajuste:** $\\;$ con un valor próximo a cero (máxima regularización)\n",
        "* **Posibilidad de sobreajuste:** $\\;$ con un valor positivo muy alto (mínima regularización)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWV6uRCthWAf"
      },
      "outputs": [],
      "source": [
        "for C in (1e-2, 1e-1, 1, 1e1, 1e2):\n",
        "    clf = LogisticRegression(C=C, random_state=23, max_iter=10000).fit(X_train, y_train)\n",
        "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
        "    print(f\"Error de test con C {C:g}: {err_test:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHX-hHqAhWAg"
      },
      "source": [
        "**Early stopping:** $\\;$ ahorramos cálculo y evitamos sobre-entrenamiento (\"regularizamos\") acabando pronto (en pocas iteraciones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D1IZzowhWAg"
      },
      "outputs": [],
      "source": [
        "# Este código evalúa cómo la limitación en el número máximo de iteraciones afecta el rendimiento del modelo.\n",
        "# Valores bajos de 'max_iter' pueden llevar a una convergencia prematura, posiblemente resultando en un modelo subóptimo.\n",
        "\n",
        "# Iterar sobre una lista de diferentes valores para el número máximo de iteraciones\n",
        "for max_iter in (10, 20, 50, 100):\n",
        "    # Crear y entrenar el modelo de regresión logística con cada valor de max_iter\n",
        "    # 'max_iter' define el número máximo de iteraciones del proceso de optimización\n",
        "    clf = LogisticRegression(random_state=23, max_iter=max_iter).fit(X_train, y_train)\n",
        "\n",
        "    # Predecir las etiquetas para el conjunto de prueba y calcular el error\n",
        "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
        "\n",
        "    # Imprimir el error de prueba para cada valor de max_iter\n",
        "    print(f\"Error de test con max_iter {max_iter}: {err_test:.1%}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz0_2DIaiUy1"
      },
      "source": [
        "**Lo ponemos todo junto**\n",
        "---\n",
        "\n",
        "Mostrar los resultados de error de test (err_test) para combinaciones de diferentes valores de:\n",
        "\n",
        "1. `max_iter` (probar valores 10, 50, 100, 200, 500, 800, 1000)\n",
        "2. `solver` (utilizar sag, saga, lbfgs y netwon-cg que son los solvers para problemas multiclase\n",
        "3. `C` (regularización: 0.01, 0.1, 1.0 , 10.0, 100)\n",
        "4. `tol` (tolerancia: probar valores 10e-4, 10e-2, 1.0, 10e2, 10e4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqDXSosgzsMb"
      },
      "outputs": [],
      "source": [
        "# Definir los parámetros a probar\n",
        "max_iters = [10, 50, 100, 200, 500, 800, 1000]\n",
        "solvers = ['sag', 'saga', 'lbfgs', 'newton-cg']\n",
        "Cs = [0.01, 0.1, 1.0, 10.0, 100]\n",
        "tols = [1e-4, 1e-2, 1, 1e2, 1e4]\n",
        "\n",
        "print('   solver     tol       C max_iter  ete')\n",
        "print('--------- ------- ------- -------- -----')\n",
        "\n",
        "# Iterar sobre las combinaciones de max_iter, solver, C y tol\n",
        "for max_iter in max_iters:\n",
        "    for solver in solvers:\n",
        "        for C in Cs:\n",
        "            for tol in tols:\n",
        "                # Crear y entrenar el modelo\n",
        "                clf = LogisticRegression(max_iter=max_iter, solver=solver, C=C, tol=tol, random_state=23).fit(X_train, y_train)\n",
        "                # Calcular el error de prueba\n",
        "                ete = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
        "                # Imprimir los resultados\n",
        "                print(f'{solver:>9} {tol:.1e} {C:.1e} {max_iter:8d} {ete:5.1%}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS5wSEs1z220"
      },
      "source": [
        "**Pregunta**:\n",
        "Indica cuál crees que es la mejor combinación de iteraciones, solver, C y tolerancia"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NR05lcmjDqgN"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}