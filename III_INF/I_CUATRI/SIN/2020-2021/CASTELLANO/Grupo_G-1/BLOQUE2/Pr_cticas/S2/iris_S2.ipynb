{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OTtF41cKsdA"
      },
      "source": [
        "# Perceptrón aplicado a iris"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeSwAg56KsdE"
      },
      "source": [
        "**Lectura del corpus:** $\\;$ comprobamos también que las matrices de datos y etiquetas tienen las filas y columnas que toca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TdDn-xUKsdE"
      },
      "outputs": [],
      "source": [
        "# Importar la biblioteca numpy y asignarle el alias 'np' para facilitar su uso posterior.\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Importar la función 'load_iris' del módulo 'datasets' de la biblioteca 'sklearn'.\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Cargar el conjunto de datos Iris y almacenarlo en la variable 'iris'.\n",
        "iris = load_iris()\n",
        "\n",
        "# Acceder a los datos de características (features) del conjunto de datos Iris, y convertirlos a 'float16'\n",
        "X = iris.data.astype(np.float16)\n",
        "\n",
        "# Acceder a las etiquetas (objetivos), convertirlas al tipo de dato 'uint' y remodelarlas para que sean una matriz de una columna\n",
        "y = iris.target.astype(np.uint).reshape(-1, 1)\n",
        "\n",
        "# Imprimir la forma (dimensiones) de las matrices 'X' y 'y', seguido de las primeras 5 filas\n",
        "print(X.shape, y.shape, \"\\n\", np.hstack([X, y])[:5, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4gNBGtBKsdG"
      },
      "source": [
        "**Partición del corpus:** $\\;$ Creamos un split de iris con un $20\\%$ de datos para test y el resto para entrenamiento (training), barajando previamente los datos de acuerdo con una semilla dada para la generación de números aleatorios. Aquí, como en todo código que incluya aleatoriedad (que requiera generar números aleatorios), conviene fijar dicha semilla para poder reproducir experimentos con exactitud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf-TXFb3KsdH"
      },
      "outputs": [],
      "source": [
        "# Importar la función 'train_test_split' del módulo 'model_selection' de la biblioteca 'sklearn'.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir los conjuntos de datos de características (X) y etiquetas (y) en subconjuntos de entrenamiento y prueba.\n",
        "# El parámetro 'test_size=0.2' indica que el 20% de los datos se utilizará como conjunto de prueba, el 80% restante será el conjunto de entrenamiento.\n",
        "# El parámetro 'shuffle=True' asegura que los datos se barajen antes de dividirlos, lo cual es importante para evitar sesgos.\n",
        "# El parámetro 'random_state=23' se utiliza para garantizar la reproducibilidad del proceso de división.\n",
        "# Los conjuntos de entrenamiento y prueba resultantes se almacenan en 'X_train', 'X_test', 'y_train' y 'y_test', respectivamente.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n",
        "\n",
        "# Imprimir las dimensiones de los conjuntos de entrenamiento y prueba de las características (X), mostrando información sobre cuántas muestras hay en cada conjunto.\n",
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBXFPalFKsdI"
      },
      "source": [
        "**Implementación de Perceptrón:** $\\;$ devuelve pesos en notación homogénea, $\\mathbf{W}\\in\\mathbb{R}^{(1+D)\\times C};\\;$ también el número de errores e iteraciones ejecutadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe_jrG3lKsdI"
      },
      "outputs": [],
      "source": [
        "def perceptron(X, y, b=0.1, a=1.0, K=200):\n",
        "    # X: Matriz de características de entrada.\n",
        "    # y: Vector de etiquetas.\n",
        "    # b: Margen de clasificación.\n",
        "    # a: Tasa de aprendizaje.\n",
        "    # K: Número máximo de iteraciones.\n",
        "\n",
        "    N, D = X.shape  # N: Número de muestras, D: Número de características.\n",
        "    Y = np.unique(y)  # Y: Etiquetas únicas en el conjunto de datos.\n",
        "    C = Y.size  # C: Número de clases únicas.\n",
        "    W = np.zeros((1+D, C))  # W: Matriz de pesos inicializada a ceros.\n",
        "\n",
        "    for k in range(1, K+1):  # Bucle sobre las iteraciones.\n",
        "        E = 0  # E: Contador de errores en la clasificación.\n",
        "\n",
        "        for n in range(N):  # Bucle sobre todas las muestras.\n",
        "            xn = np.array([1, *X[n, :]])  # xn: Vector de características con un término de sesgo añadido.\n",
        "            cn = np.squeeze(np.where(Y==y[n]))  # cn: Índice de la clase actual de la muestra.\n",
        "            gn = W[:,cn].T @ xn  # gn: Producto punto de la muestra con los pesos de su clase.\n",
        "            err = False  # err: Indicador de error en la clasificación.\n",
        "\n",
        "            # Bucle para actualizar los pesos si se encuentra un error.\n",
        "            for c in np.arange(C):\n",
        "                if c != cn and W[:,c].T @ xn + b >= gn:\n",
        "                    W[:, c] = W[:, c] - a*xn  # Actualizar pesos para clases incorrectas.\n",
        "                    err = True\n",
        "\n",
        "            # Actualizar pesos para la clase correcta si se encontró un error.\n",
        "            if err:\n",
        "                W[:, cn] = W[:, cn] + a*xn\n",
        "                E = E + 1  # Incrementar el contador de errores.\n",
        "\n",
        "        # Si no hay errores, detener el entrenamiento.\n",
        "        if E == 0:\n",
        "            break;\n",
        "\n",
        "    return W, E, k  # Devolver la matriz de pesos, el número de errores y el número de iteraciones realizadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VF6RK2XKsdJ"
      },
      "source": [
        "**Aprendizaje de un clasificador (lineal) con Perceptrón:** $\\;$ Perceptrón minimiza el número de errores de entrenamiento (con margen)\n",
        "$$\\mathbf{W}^*=\\operatorname*{argmin}_{\\mathbf{W}=(\\boldsymbol{w}_1,\\dotsc,\\boldsymbol{w}_C)}\\sum_n\\;\\mathbb{Y}\\biggl(\\max_{c\\neq y_n}\\;\\boldsymbol{w}_c^t\\boldsymbol{x}_n+b \\;>\\; \\boldsymbol{w}_{y_n}^t\\boldsymbol{x}_n\\biggr)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhrGnz5dKsdK"
      },
      "outputs": [],
      "source": [
        "W, E, k = perceptron(X_train, y_train)\n",
        "print(\"Número de iteraciones ejecutadas: \", k)\n",
        "print(\"Número de errores de entrenamiento: \", E)\n",
        "print(\"Vectores de pesos de las clases (en columnas y en notación homogénea):\\n\", W);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2G-5pYWKsdK"
      },
      "source": [
        "**Cálculo de la tasa de error en test:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZskvvO8ZKsdK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Preparar el conjunto de datos de prueba (X_test) para la clasificación.\n",
        "# Esto se hace añadiendo una columna de unos al inicio de X_test.\n",
        "# La columna de unos actúa como un término de sesgo en el modelo de perceptrón.\n",
        "X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
        "\n",
        "# Realizar la predicción en el conjunto de prueba.\n",
        "# Esto se hace calculando el producto punto (usando el operador '@') entre X_testh y la matriz de pesos W.\n",
        "# La función 'np.argmax' se usa para seleccionar el índice de la clase con el valor más alto en cada fila,\n",
        "# lo que corresponde a la clase predicha por el modelo.\n",
        "# Los resultados se reforman en una matriz de una columna.\n",
        "y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
        "\n",
        "# Calcular la tasa de error de las predicciones.\n",
        "# Esto se hace contando el número de veces que las predicciones (y_test_pred) difieren de las etiquetas verdaderas (y_test),\n",
        "# y dividiendo este número por la longitud del conjunto de prueba (X_test).\n",
        "# El resultado es la proporción de predicciones incorrectas.\n",
        "err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
        "\n",
        "# Imprimir la tasa de error en el conjunto de prueba.\n",
        "# El resultado se muestra como un porcentaje con un decimal.\n",
        "print(f\"Tasa de error en test: {err_test:.1%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n163LOiTKsdL"
      },
      "source": [
        "**Ajuste del margen:** $\\;$ experimento para aprender un valor de $b$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O_xIOmTKsdL"
      },
      "outputs": [],
      "source": [
        "# Bucle sobre diferentes valores del parámetro de margen 'b'.\n",
        "for b in (.0, .01, .1, 10, 100):\n",
        "    # Entrenar el perceptrón con el conjunto de entrenamiento (X_train, y_train), utilizando el valor actual de 'b' y un límite máximo de 1000 iteraciones.\n",
        "    # La función 'perceptron' devuelve la matriz de pesos 'W', el número de errores 'E' y el número de iteraciones 'k'.\n",
        "    W, E, k = perceptron(X_train, y_train, b=b, K=1000)\n",
        "\n",
        "    # Imprimir el valor actual de 'b', el número de errores 'E', y el número de iteraciones 'k' para cada entrenamiento.\n",
        "    print(b, E, k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uloTj-7uKsdM"
      },
      "source": [
        "**Interpretación de resultados:** $\\;$ los datos de entrenamiento no parecen linealmente separables; no está claro que un margen mayor que cero pueda mejorar resultados, sobre todo porque solo tenemos $30$ muestras de test; con margen .1 ya hemos visto que se obtiene un error (en test) del $16.7\\%$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iteramos con b y calculamos error"
      ],
      "metadata": {
        "id": "62wmHk1TbAeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for b in (.0, .01, .1, 10, 50):\n",
        "\n",
        "    W, E, k = perceptron(X_train, y_train, b=b, K=1000)\n",
        "\n",
        "    X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
        "\n",
        "    y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
        "\n",
        "    err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
        "\n",
        "    print(f\"Iteracion con b: {b} Tasa de error en test: {err_test:.1%}\")"
      ],
      "metadata": {
        "id": "opmlRUmtVVXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iteramos con a y calculamos error"
      ],
      "metadata": {
        "id": "y361ewbAbGKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for a in ( .01, .1, 10, 100):\n",
        "\n",
        "    W, E, k = perceptron(X_train, y_train, b=50, a=a, K=1000)\n",
        "\n",
        "    X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
        "\n",
        "    y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
        "\n",
        "    err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
        "\n",
        "    print(f\"Iteracion con a: {a} Tasa de error en test: {err_test:.1%}\")"
      ],
      "metadata": {
        "id": "96ZIL1nTVZgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iteramos con el numero máximo de iteraciones y calculamos error"
      ],
      "metadata": {
        "id": "X1hGAi10bIvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in ( 200, 500, 1000, 10000):\n",
        "\n",
        "    W, E, k = perceptron(X_train, y_train, a=0.01, b=50, K=k)\n",
        "\n",
        "    X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
        "\n",
        "    y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
        "\n",
        "    err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
        "\n",
        "    print(f\"Iteracion con k: {k} Tasa de error en test: {err_test:.1%}\")"
      ],
      "metadata": {
        "id": "tvgs8liZVcB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué combinación de valores de a, b y k seleccionarias? Justifica la respuesta"
      ],
      "metadata": {
        "id": "opC8-nltU0wb"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}